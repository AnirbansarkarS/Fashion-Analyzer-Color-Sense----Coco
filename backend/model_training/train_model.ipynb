{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionModel:\n",
    "    \"\"\"\n",
    "    Fashion scoring model using CNN\n",
    "    Can be fine-tuned with custom dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(224, 224, 3)):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build CNN model with transfer learning (MobileNetV2)\n",
    "        \"\"\"\n",
    "        # Load pre-trained MobileNetV2\n",
    "        base_model = keras.applications.MobileNetV2(\n",
    "            input_shape=self.input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        \n",
    "        # Freeze base model layers\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Add custom top layers\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')  # Output: 0-1 (normalized score)\n",
    "        ])\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load pre-trained model\"\"\"\n",
    "        try:\n",
    "            self.model = keras.models.load_model(model_path)\n",
    "            print(f\"âœ“ Model loaded from {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error loading model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def save_model(self, model_path):\n",
    "        \"\"\"Save model\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"âœ— Model not built yet\")\n",
    "            return\n",
    "        \n",
    "        Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.model.save(model_path)\n",
    "        print(f\"âœ“ Model saved to {model_path}\")\n",
    "    \n",
    "    def train(self, X_train=None, y_train=None, X_val=None, y_val=None, \n",
    "              epochs=20, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        If no data provided, uses synthetic data for demo\n",
    "        \"\"\"\n",
    "        \n",
    "        # If no training data provided, create synthetic data\n",
    "        if X_train is None:\n",
    "            print(\"âš  No training data provided. Using synthetic data for demo...\")\n",
    "            X_train = np.random.rand(100, 224, 224, 3).astype('float32')\n",
    "            y_train = np.random.rand(100, 1).astype('float32')\n",
    "            X_val = np.random.rand(20, 224, 224, 3).astype('float32')\n",
    "            y_val = np.random.rand(20, 1).astype('float32')\n",
    "        \n",
    "        # Build model if not already built\n",
    "        if self.model is None:\n",
    "            self.build_model()\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=3,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=2,\n",
    "                min_lr=1e-7\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train\n",
    "        print(\"\\nðŸš€ Starting model training...\")\n",
    "        self.history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"âœ“ Training complete!\")\n",
    "        return self.history\n",
    "    \n",
    "    def predict(self, image, return_features=False):\n",
    "        \"\"\"\n",
    "        Predict fashion score for image\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"âœ— Model not loaded\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Ensure correct shape\n",
    "            if len(image.shape) == 3:\n",
    "                image = np.expand_dims(image, axis=0)\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.model.predict(image, verbose=0)[0][0]\n",
    "            score = prediction * 10  # Scale from 0-10\n",
    "            \n",
    "            if return_features:\n",
    "                # Extract intermediate features\n",
    "                feature_extractor = models.Model(\n",
    "                    inputs=self.model.input,\n",
    "                    outputs=self.model.layers[-3].output\n",
    "                )\n",
    "                features = feature_extractor.predict(image, verbose=0)\n",
    "                \n",
    "                return {\n",
    "                    'score': score,\n",
    "                    'features': features.flatten()\n",
    "                }\n",
    "            \n",
    "            return {\n",
    "                'style_match': score / 10,\n",
    "                'texture_quality': (score / 10) * 0.9,\n",
    "                'confidence': float(prediction)\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in prediction: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"Evaluate model on test data\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"âœ— Model not loaded\")\n",
    "            return None\n",
    "        \n",
    "        loss, mae = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Test Loss: {loss:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        return {'loss': loss, 'mae': mae}\n",
    "    \n",
    "    def fine_tune(self, X_train, y_train, X_val, y_val, epochs=10):\n",
    "        \"\"\"\n",
    "        Fine-tune model with custom dataset\n",
    "        Unfreezes some base model layers\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"âœ— Model not built yet\")\n",
    "            return\n",
    "        \n",
    "        # Unfreeze last 50 layers of base model\n",
    "        for layer in self.model.layers[0].layers[-50:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        # Use lower learning rate for fine-tuning\n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        print(\"ðŸ”§ Fine-tuning model...\")\n",
    "        self.history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=16,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"âœ“ Fine-tuning complete!\")\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataGenerator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    \"\"\"Generate training data from fashion datasets\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_fashion_mnist():\n",
    "        \"\"\"Load Fashion-MNIST dataset for quick prototyping\"\"\"\n",
    "        from tensorflow.keras.datasets import fashion_mnist\n",
    "        \n",
    "        (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "        \n",
    "        # Convert to 224x224 for model input\n",
    "        X_train = np.repeat(np.expand_dims(X_train, axis=-1), 3, axis=-1)\n",
    "        X_test = np.repeat(np.expand_dims(X_test, axis=-1), 3, axis=-1)\n",
    "        \n",
    "        # Resize\n",
    "        from tensorflow.image import resize\n",
    "        X_train = resize(X_train, (224, 224)).numpy()\n",
    "        X_test = resize(X_test, (224, 224)).numpy()\n",
    "        \n",
    "        # Normalize\n",
    "        X_train = X_train.astype('float32') / 255.0\n",
    "        X_test = X_test.astype('float32') / 255.0\n",
    "        \n",
    "        # Create regression targets (0-1 scores)\n",
    "        y_train = (y_train / 10.0).astype('float32').reshape(-1, 1)\n",
    "        y_test = (y_test / 10.0).astype('float32').reshape(-1, 1)\n",
    "        \n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_custom_dataset(data_dir, img_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Load custom fashion dataset from directory\n",
    "        Expected structure: data_dir/score_1-10/image.jpg\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "        \n",
    "        images = []\n",
    "        scores = []\n",
    "        \n",
    "        for score_dir in os.listdir(data_dir):\n",
    "            score_path = os.path.join(data_dir, score_dir)\n",
    "            if not os.path.isdir(score_path):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                score = float(score_dir) / 10.0\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for img_file in os.listdir(score_path):\n",
    "                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_path = os.path.join(score_path, img_file)\n",
    "                    try:\n",
    "                        img = load_img(img_path, target_size=img_size)\n",
    "                        img_array = img_to_array(img) / 255.0\n",
    "                        images.append(img_array)\n",
    "                        scores.append(score)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        X = np.array(images)\n",
    "        y = np.array(scores).reshape(-1, 1)\n",
    "        \n",
    "        return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
